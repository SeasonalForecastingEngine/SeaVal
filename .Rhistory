pdf(paste0(plot_dir,'ibs.pdf'))
plot_diagnostic(dt_fc,'ibs')
dev.off()
pdf(paste0(plot_dir,'rps_minus_clim.pdf'))
plot_diagnostic(dt_fc[,.(lon,lat,rps - rps_clim)], rr = c(-0.33,0.33),mn = 'rps - rps_clim')
dev.off()
pdf(paste0(plot_dir,'ibs_minus_clim.pdf'))
plot_diagnostic(dt_fc[,.(lon,lat,ibs - 2/3)], rr = c(-0.33,0.33))
dev.off()
pdf(paste0(plot_dir,'ibs_minus_clim.pdf'))
plot_diagnostic(dt_fc[,.(lon,lat,ibs - 2/3)], rr = c(-0.33,0.33),mn = 'ibs - ibs_clim')
dev.off()
dt_fc
pdf(paste0(plot_dir,'below.pdf'))
plot_diagnostic(dt_fc,'below')
dev.off()
pdf(paste0(plot_dir,'normal.pdf'))
plot_diagnostic(dt_fc,'normal')
dev.off()
pdf(paste0(plot_dir,'above.pdf'))
plot_diagnostic(dt_fc,'above')
dev.off()
pdf(paste0(plot_dir,'prec_cat.pdf'))
plot_diagnostic(dt_fc,'prec_cat')
dev.off()
pdf(paste0(plot_dir,'below.pdf'))
plot_diagnostic(dt_fc,'below',rr = c(0,0.67))
dev.off()
pdf(paste0(plot_dir,'normal.pdf'))
plot_diagnostic(dt_fc,'normal',rr = c(0,0.67))
dev.off()
pdf(paste0(plot_dir,'above.pdf'))
plot_diagnostic(dt_fc,'above',rr = c(0,0.67))
dev.off()
pdf(paste0(plot_dir,'prec_cat.pdf'))
plot_diagnostic(dt_fc,'prec_cat')
dev.off()
knitr::opts_chunk$set(echo = TRUE)
# load the postprocessing package:
devtools::load_all()
# get ERA observation data:
era_dt = load_era_monthly_data('total_precipitation',months = 2:4,years = 1980:2021,
lon_subset = global_confer_lon_subset(), lat_subset = global_confer_lat_subset(),
root_dir = claudio_sfe_dir())
get_terciles = function(dt,SDcols,bycols,copy = T)
{
if(copy)
{
dt_new = copy(dt)
} else { dt_new = dt  }
terc_fct = function(x){-1*(x <= quantile(x,0.33,na.rm = T)) + 1*(x >= quantile(x,0.67,na.rm = T))}
dt_new[,paste0(SDcols,'_cat') := lapply(.SD,terc_fct),.SDcols = SDcols,by = bycols]
return(dt_new)
}
era_dt = era_dt[month %in% 2:3,.(prec = mean(total_precipitation)),by = .(year,lon,lat)]
era_cats = get_terciles(era_dt,'prec',c('lon','lat'))
plot_diagnostic(dt_fc,'below',rr = c(0.1,0.56))
plot_diagnostic(dt_fc,'normal',rr = c(0.1,0.56))
plot_diagnostic(dt_fc,'above',rr = c(0.1,0.56))
plot_diagnostic
dt_fc
nc = nc_open(paste0(data_dir,'202101/PredictedRainfallProbbability-FMA2021_Jan2021.nc'))
lons = ncvar_get(nc,varid = 'lon')
lats = ncvar_get(nc,varid = 'lat')
dt_fc = data.table(Lon = rep(lons,length(lats)),
Lat = rep(lats,each = length(lons)),
below = as.vector(ncvar_get(nc,varid = 'below')),
normal = as.vector(ncvar_get(nc,varid = 'normal')),
above = as.vector(ncvar_get(nc,varid = 'above')))
# remove missing values:
dt_fc = dt_fc[!is.na(below)]
# transform probabilities from percent to probabilities between 0 and 1:
dt_fc = dt_fc[,lapply(.SD,function(x) x/100),.SDcols = c('below','normal','above')]
print(dt_fc)
# load the postprocessing package:
devtools::load_all()
plot_diagnostic(dt_fc,'below',rr = c(0.1,0.56))
?plot_diagnostic
rm(list = ls())
# load the postprocessing package:
devtools::load_all()
# get ERA observation data:
era_dt = load_era_monthly_data('total_precipitation',months = 2:4,years = 1980:2021,
lon_subset = global_confer_lon_subset(), lat_subset = global_confer_lat_subset(),
root_dir = claudio_sfe_dir())
get_terciles = function(dt,SDcols,bycols,copy = T)
{
if(copy)
{
dt_new = copy(dt)
} else { dt_new = dt  }
terc_fct = function(x){-1*(x <= quantile(x,0.33,na.rm = T)) + 1*(x >= quantile(x,0.67,na.rm = T))}
dt_new[,paste0(SDcols,'_cat') := lapply(.SD,terc_fct),.SDcols = SDcols,by = bycols]
return(dt_new)
}
era_dt = era_dt[month %in% 2:3,.(prec = mean(total_precipitation)),by = .(year,lon,lat)]
era_cats = get_terciles(era_dt,'prec',c('lon','lat'))
era_cats = era_cats[year == 2021]
setnames(era_cats,c('lon','lat'),c('Lon','Lat'))
rmarkdown::render('tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
getwd()
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
library(pdf)
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rm(list = ls())
# load the postprocessing package:
devtools::load_all()
library(data.table)
library(ncdf4)
data_dir = '/nr/project/stat/CONFER/Data/validation/example_data/'
nc = nc_open(paste0(data_dir,'202101/PredictedRainfallProbbability-FMA2021_Jan2021.nc'))
### sort all the nc-values into an R data.table
lons = ncvar_get(nc,varid = 'lon')
lats = ncvar_get(nc,varid = 'lat')
dt_fc = data.table(Lon = rep(lons,length(lats)),
Lat = rep(lats,each = length(lons)),
below = as.vector(ncvar_get(nc,varid = 'below')),
normal = as.vector(ncvar_get(nc,varid = 'normal')),
above = as.vector(ncvar_get(nc,varid = 'above')))
# remove missing values:
dt_fc = dt_fc[!is.na(below)]
# transform probabilities from percent to probabilities between 0 and 1:
dt_fc = dt_fc[,c('below','normal','above') := lapply(.SD,function(x) x/100),.SDcols = c('below','normal','above')]
# get ERA observation data:
era_dt = load_era_monthly_data('total_precipitation',months = 2:4,years = 1980:2021,
lon_subset = global_confer_lon_subset(), lat_subset = global_confer_lat_subset(),
root_dir = claudio_sfe_dir())
get_terciles = function(dt,SDcols,bycols,copy = T)
{
if(copy)
{
dt_new = copy(dt)
} else { dt_new = dt  }
terc_fct = function(x){-1*(x <= quantile(x,0.33,na.rm = T)) + 1*(x >= quantile(x,0.67,na.rm = T))}
dt_new[,paste0(SDcols,'_cat') := lapply(.SD,terc_fct),.SDcols = SDcols,by = bycols]
return(dt_new)
}
era_dt = era_dt[month %in% 2:3,.(prec = mean(total_precipitation)),by = .(year,lon,lat)]
era_cats = get_terciles(era_dt,'prec',c('lon','lat'))
era_cats = era_cats[year == 2021]
setnames(era_cats,c('lon','lat'),c('Lon','Lat'))
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
dt_fc
rm(list = ls())
# load the postprocessing package:
devtools::load_all()
library(data.table)
library(ncdf4)
data_dir = '/nr/project/stat/CONFER/Data/validation/example_data/'
nc = nc_open(paste0(data_dir,'202101/PredictedRainfallProbbability-FMA2021_Jan2021.nc'))
### sort all the nc-values into an R data.table
lons = ncvar_get(nc,varid = 'lon')
lats = ncvar_get(nc,varid = 'lat')
dt_fc = data.table(Lon = rep(lons,length(lats)),
Lat = rep(lats,each = length(lons)),
below = as.vector(ncvar_get(nc,varid = 'below')),
normal = as.vector(ncvar_get(nc,varid = 'normal')),
above = as.vector(ncvar_get(nc,varid = 'above')))
# remove missing values:
dt_fc = dt_fc[!is.na(below)]
# transform probabilities from percent to probabilities between 0 and 1:
dt_fc = dt_fc[,c('below','normal','above') := lapply(.SD,function(x) x/100),.SDcols = c('below','normal','above')]
# get ERA observation data:
era_dt = load_era_monthly_data('total_precipitation',months = 2:4,years = 1980:2021,
lon_subset = global_confer_lon_subset(), lat_subset = global_confer_lat_subset(),
root_dir = claudio_sfe_dir())
get_terciles = function(dt,SDcols,bycols,copy = T)
{
if(copy)
{
dt_new = copy(dt)
} else { dt_new = dt  }
terc_fct = function(x){-1*(x <= quantile(x,0.33,na.rm = T)) + 1*(x >= quantile(x,0.67,na.rm = T))}
dt_new[,paste0(SDcols,'_cat') := lapply(.SD,terc_fct),.SDcols = SDcols,by = bycols]
return(dt_new)
}
era_dt = era_dt[month %in% 2:3,.(prec = mean(total_precipitation)),by = .(year,lon,lat)]
era_cats = get_terciles(era_dt,'prec',c('lon','lat'))
era_cats = era_cats[year == 2021]
setnames(era_cats,c('lon','lat'),c('Lon','Lat'))
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rm(list = ls())
# load the postprocessing package:
devtools::load_all()
library(data.table)
library(ncdf4)
data_dir = '/nr/project/stat/CONFER/Data/validation/example_data/'
nc = nc_open(paste0(data_dir,'202101/PredictedRainfallProbbability-FMA2021_Jan2021.nc'))
### sort all the nc-values into an R data.table
lons = ncvar_get(nc,varid = 'lon')
lats = ncvar_get(nc,varid = 'lat')
dt_fc = data.table(Lon = rep(lons,length(lats)),
Lat = rep(lats,each = length(lons)),
below = as.vector(ncvar_get(nc,varid = 'below')),
normal = as.vector(ncvar_get(nc,varid = 'normal')),
above = as.vector(ncvar_get(nc,varid = 'above')))
# remove missing values:
dt_fc = dt_fc[!is.na(below)]
# transform probabilities from percent to probabilities between 0 and 1:
dt_fc = dt_fc[,c('below','normal','above') := lapply(.SD,function(x) x/100),.SDcols = c('below','normal','above')]
# get ERA observation data:
era_dt = load_era_monthly_data('total_precipitation',months = 2:4,years = 1980:2021,
lon_subset = global_confer_lon_subset(), lat_subset = global_confer_lat_subset(),
root_dir = claudio_sfe_dir())
get_terciles = function(dt,SDcols,bycols,copy = T)
{
if(copy)
{
dt_new = copy(dt)
} else { dt_new = dt  }
terc_fct = function(x){-1*(x <= quantile(x,0.33,na.rm = T)) + 1*(x >= quantile(x,0.67,na.rm = T))}
dt_new[,paste0(SDcols,'_cat') := lapply(.SD,terc_fct),.SDcols = SDcols,by = bycols]
return(dt_new)
}
era_dt = era_dt[month %in% 2:3,.(prec = mean(total_precipitation)),by = .(year,lon,lat)]
era_cats = get_terciles(era_dt,'prec',c('lon','lat'))
era_cats = era_cats[year == 2021]
setnames(era_cats,c('lon','lat'),c('Lon','Lat'))
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.height = 6)
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rm(list = ls())
# load the postprocessing package:
devtools::load_all()
library(data.table)
library(ncdf4)
data_dir = '/nr/project/stat/CONFER/Data/validation/example_data/'
nc = nc_open(paste0(data_dir,'202101/PredictedRainfallProbbability-FMA2021_Jan2021.nc'))
### sort all the nc-values into an R data.table
lons = ncvar_get(nc,varid = 'lon')
lats = ncvar_get(nc,varid = 'lat')
dt_fc = data.table(Lon = rep(lons,length(lats)),
Lat = rep(lats,each = length(lons)),
below = as.vector(ncvar_get(nc,varid = 'below')),
normal = as.vector(ncvar_get(nc,varid = 'normal')),
above = as.vector(ncvar_get(nc,varid = 'above')))
# remove missing values:
dt_fc = dt_fc[!is.na(below)]
# transform probabilities from percent to probabilities between 0 and 1:
dt_fc = dt_fc[,c('below','normal','above') := lapply(.SD,function(x) x/100),.SDcols = c('below','normal','above')]
# get ERA observation data:
era_dt = load_era_monthly_data('total_precipitation',months = 2:4,years = 1980:2021,
lon_subset = global_confer_lon_subset(), lat_subset = global_confer_lat_subset(),
root_dir = claudio_sfe_dir())
get_terciles = function(dt,SDcols,bycols,copy = T)
{
if(copy)
{
dt_new = copy(dt)
} else { dt_new = dt  }
terc_fct = function(x){-1*(x <= quantile(x,0.33,na.rm = T)) + 1*(x >= quantile(x,0.67,na.rm = T))}
dt_new[,paste0(SDcols,'_cat') := lapply(.SD,terc_fct),.SDcols = SDcols,by = bycols]
return(dt_new)
}
era_dt = era_dt[month %in% 2:3,.(prec = mean(total_precipitation)),by = .(year,lon,lat)]
era_cats = get_terciles(era_dt,'prec',c('lon','lat'))
era_cats = era_cats[year == 2021]
setnames(era_cats,c('lon','lat'),c('Lon','Lat'))
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval_pres.Rmd')
library(rgdal)
install.package('sf')
install.packages('sf')
install.packages("sf")
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rm(list = ls())
# load the postprocessing package:
devtools::load_all()
library(data.table)
library(ncdf4)
data_dir = '/nr/project/stat/CONFER/Data/validation/example_data/'
nc = nc_open(paste0(data_dir,'202101/PredictedRainfallProbbability-FMA2021_Jan2021.nc'))
### sort all the nc-values into an R data.table
lons = ncvar_get(nc,varid = 'lon')
lats = ncvar_get(nc,varid = 'lat')
dt_fc = data.table(Lon = rep(lons,length(lats)),
Lat = rep(lats,each = length(lons)),
below = as.vector(ncvar_get(nc,varid = 'below')),
normal = as.vector(ncvar_get(nc,varid = 'normal')),
above = as.vector(ncvar_get(nc,varid = 'above')))
# remove missing values:
dt_fc = dt_fc[!is.na(below)]
# transform probabilities from percent to probabilities between 0 and 1:
dt_fc = dt_fc[,c('below','normal','above') := lapply(.SD,function(x) x/100),.SDcols = c('below','normal','above')]
# get ERA observation data:
era_dt = load_era_monthly_data('total_precipitation',months = 2:4,years = 1980:2021,
lon_subset = global_confer_lon_subset(), lat_subset = global_confer_lat_subset(),
root_dir = claudio_sfe_dir())
get_terciles = function(dt,SDcols,bycols,copy = T)
{
if(copy)
{
dt_new = copy(dt)
} else { dt_new = dt  }
terc_fct = function(x){-1*(x <= quantile(x,0.33,na.rm = T)) + 1*(x >= quantile(x,0.67,na.rm = T))}
dt_new[,paste0(SDcols,'_cat') := lapply(.SD,terc_fct),.SDcols = SDcols,by = bycols]
return(dt_new)
}
era_dt = era_dt[month %in% 2:3,.(prec = mean(total_precipitation)),by = .(year,lon,lat)]
era_cats = get_terciles(era_dt,'prec',c('lon','lat'))
era_cats = era_cats[year == 2021]
setnames(era_cats,c('lon','lat'),c('Lon','Lat'))
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
dt_fc
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.height = 6)
# This RMarkdown file is not fully self-contained. Knit this from the file tercile_eval.R!!!
bss = function(p1_vec,p2_vec,p3_vec,obs_vec)
{
bss = 3/2 *(2/3 - ((obs_vec == -1) - p1_vec)^2 +  ((obs_vec == 0) -  p2_vec)^2 + ((obs_vec == 1) - p3_vec)^2)
return(bss)
}
# append observation to prediction:
dt_fc_new = merge(dt_fc,era_cats[,.(Lon,Lat,prec_cat)],by = c('Lon','Lat'))
bss = function(p1_vec,p2_vec,p3_vec,obs_vec)
{
bss = 3/2 *(2/3 - ((obs_vec == -1) - p1_vec)^2 +  ((obs_vec == 0) -  p2_vec)^2 + ((obs_vec == 1) - p3_vec)^2)
return(bss)
}
# get BSS:
dt_fc_new[,bss := bss(below,normal,above,prec_cat)]
dt_fc_new
bss = function(p1_vec,p2_vec,p3_vec,obs_vec)
{
bss = 3/2 *(2/3 - (((obs_vec == -1) - p1_vec)^2 +  ((obs_vec == 0) -  p2_vec)^2 + ((obs_vec == 1) - p3_vec)^2))
return(bss)
}
# get BSS:
dt_fc_new[,bss := bss(below,normal,above,prec_cat)]
dt_fc_new
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
rmarkdown::render('/nr/user/claudio/pkg/PostProcessing/scripts/CONFER/validation/tercile_eval.Rmd')
getwd()
q(save = 'no')
q(save = 'no')
q(save = 'no')
q(save = 'no')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.height = 6)
cv_dt[,prec_ano := prec - mean(prec), by = .(lon,lat)] # derive anomaly for each gridpoint
rm(list = ls())
library(data.table)
library(sp)
library(dplyr)
library(raster)
data_dir = '/nr/project/stat/CONFER/Data/'
data = getData('GADM')
country_list = c('Sudan','South Sudan','Ethiopia','Eritrea','Somalia','Kenya','Tanzania','Uganda','Rwanda','Djibouti','Burundi')
ISOs = as.data.table(getData('ISO3'))[NAME %in% country_list]
# weirdly enough, the getData function does not support doing multiple countries at the same time:
iso1 = ISOs[1,ISO3]
country1 = getData('GADM', country = iso1,level = 0)
pols = polygons(country1)
for(iso in ISOs[2:.N,ISO3])
{
cc = getData('GADM', country = iso,level = 0)
pols = rbind(pols, polygons(cc), makeUniqueIDs = TRUE)
}
pols
is(pols)
plot(pols)
ISOs
pols
pols$`1`
features(pols)
rm(list = ls())
library(data.table)
library(sp)
library(dplyr)
library(raster)
data_dir = '/nr/project/stat/CONFER/Data/'
data = getData('GADM')
country_list = c('Sudan','South Sudan','Ethiopia','Eritrea','Somalia','Kenya','Tanzania','Uganda','Rwanda','Djibouti','Burundi')
ISOs = as.data.table(getData('ISO3'))[NAME %in% country_list]
# weirdly enough, the getData function does not support doing multiple countries at the same time:
iso1 = ISOs[1,ISO3]
country1 = getData('GADM', country = iso1,level = 0)
pols = polygons(country1)
for(iso in ISOs[2:.N,ISO3])
{
cc = getData('GADM', country = iso,level = 0)
pols = rbind(pols, polygons(cc), makeUniqueIDs = TRUE)
}
### for full- and half-degree grids get the within-ICPAC locations as data.table:
full_deg_locs = as.data.table(expand.grid(lon = -179:180,lat = -90:90))
locs = SpatialPoints(full_deg_locs,proj4string = crs(pols))
full_deg_locs = as.data.table(coordinates(locs))[!is.na(over(locs,pols)),]
setkey(full_deg_locs,lon,lat)
half_deg_locs = as.data.table(expand.grid(lon = seq(-179,180,0.5),lat = seq(-90,90,0.5)))
locs = SpatialPoints(half_deg_locs,proj4string = crs(pols))
half_deg_locs = as.data.table(coordinates(locs))[!is.na(over(locs,pols)),]
setkey(half_deg_locs,lon,lat)
ICPAC_borders = copy(pols)
# save:
save(ICPAC_borders,full_deg_locs,half_deg_locs,file = paste0(data_dir,'ICPAC_region.RData'))
#######################
countriesSP = getMap(resolution = 'high')
library(rworldmap)
countriesSP = getMap(resolution = 'high')
full_deg_locs
test = SpatialPoints(half_deg_locs,proj4string = CRS(countriesSP))
test = SpatialPoints(half_deg_locs,proj4string = CRS(proj4string(countriesSP)))
test
temp = SpatialPoints(half_deg_locs,proj4string = CRS(proj4string(countriesSP)))
indices = over(temp,countriesSP)
indices$ADMIN
unique(indices$ADMIN)
half_deg_locs[,country := indices$ADMIN]
ggplot_dt(half_deg_locs,'country')
library(PostProcessing)
ggplot_dt(half_deg_locs,'country')
plot_diagnostic(half_deg_locs,'country')
half_deg_locs
cs = unique(indices$ADMIN)
half_deg_locs[,country_ind := match(country,cs)]
ggplot_dt(half_deg_locs,'country_ind')
cs
nonGHAcs = c('Libya','Egypt','United Republic of Tanzania','Malawi','Mozambique','Somaliland')
correctedcs = c('Sudan','Sudan','Tanzania','Tanzania','Tanzania','Somalia')
correct_countries = function(cs)
{
cs_new = cs
cs_new[cs_new %in% nonGHAcs] = correctedcs[match(cs_new[cs_new %in% nonGHAcs],nonGHAcs)]
}
correct_countries = function(cs)
{
cs_new = cs
cs_new[cs_new %in% nonGHAcs] = correctedcs[match(cs_new[cs_new %in% nonGHAcs],nonGHAcs)]
return(cs_new)
}
half_deg_locs[,country := correct_countries(country)]
cs = half_deg_locs[,country]
cs
cs_new = cs
cs_new[cs_new %in% nonGHAcs]
cs_new = as.character(cs)
cs_new[cs_new %in% nonGHAcs] = correctedcs[match(cs_new[cs_new %in% nonGHAcs],nonGHAcs)]
correct_countries = function(cs)
{
cs_new = as.character(cs)
cs_new[cs_new %in% nonGHAcs] = correctedcs[match(cs_new[cs_new %in% nonGHAcs],nonGHAcs)]
return(cs_new)
}
half_deg_locs[,country := correct_countries(country)]
half_deg_locs
half_deg_locs[,unique(country)]
half_deg_locs[,.(Lon,Lat,country_ind) := NULL]
half_deg_locs[,c('Lon','Lat','country_ind') := NULL]
half_deg_locs
fwrite(half_deg_locs,file = '/nr/project/stat/CONFER/Data/GHAcountries.csv')
add_countries = function(dt,countryfile = '/nr/project/stat/CONFER/Data/GHAcountries.csv')
{
cs = fread(countryfile)
return(merge(dt,cs,by = c('lon','lat')))
}
mse_dt = add_countries(mse_dt)
q(save = 'no')
install.packages('devtools')
devtools::install_github('SeasonalForecastingEngine/ForecastTools')
devtools::install_github('SeasonalForecastingEngine/SeaVal')
library(data.table)
library(ForecastTools)
library(SeaVal)
data_dir = '/nr/project/stat/CONFER/Data/validation/example_data/202101/'
cv_dt = cv_to_dt(data_dir)
devtools::document()
setwd(../SeaVal)
setwd('../SeaVal')
devtools::document()
cv_dt = cv_to_dt(data_dir)
q(save = 'no')
