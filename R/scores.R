#' Calculate exceedence Brier score
#'
#' @param dt Data table containing the predictions.
#' @param fc column name of the prediction. Contains predicted probabilities of exceedence
#' @param threshold_col which column contains the exceedence threshold?
#' @param obs column name of the observations. Can either be logical (exceedence or not) or real valued, containing precipitation (or the variable for which exceedence should be checked).
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) over which is averaged. Typically just 'year'.
#' @export

BS_ex_dt = function(dt,fc,threshold_col,
                    obs = 'obs',
                    by = intersect(c('month','season','lon','lat','system','lead_time'),names(dt)),
                    pool = c('year'))
{
  if(range(dt[,get(fc)],na.rm = T)[2] > 1) stop('your predictions should be values between 0 and 1.')
  if(is.logical(dt[,get(obs)]))
  {
    Score_dt = dt[,.(BS_ex = (get(fc)-get(obs))^2),by = c(by,threshold_col)]# the by-arguments are for keeping these columns only
  }
  if(!is.logical(dt[,get(obs)]))
  {
    Score_dt = dt[,.(BS_ex = (get(fc) - (get(obs) > get(threshold_col)))^2),by = c(by,threshold_col)]
  }
  return(Score_dt)
}



#' Calculate exceedence Brier skill score
#'
#' @param dt Data table containing the predictions.
#' @param fc column name of the prediction. Contains predicted probabilities of exceedence
#' @param clim_col column name containing the out-of-sample climatology forecast for the exceedence probability.
#' Usually generated by \code{climatology_threshold_exceedence}.
#' @param threshold_col which column contains the exceedence threshold?
#' @param obs column name of the observations. Can either be logical (exceedence or not) or real valued, containing precipitation (or the variable for which exceedence should be checked).
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @export

BSS_ex_dt = function(dt,
                     fc,
                     clim_col = 'clim',
                     threshold_col,
                     obs = 'obs',
                     by = intersect(c('month','season','lon','lat','system','lead_time'),names(dt)))
{
  # for devtools::check:
  BSS_ex = clim_BS_ex = BS_ex = NULL


  BS_dt = BS_ex_dt(dt = dt,
                   fc = fc,
                   threshold_col = threshold_col,
                   obs = obs,
                   by = by)

  clim_es_dt = BS_ex_dt(dt = dt,
                        fc = clim_col,
                        threshold_col = threshold_col,
                        obs = obs,
                        by = by)


  setnames(clim_es_dt,'BS_ex','clim_BS_ex')
  score_dt = merge(BS_dt,clim_es_dt,by = intersect(names(BS_dt),names(clim_es_dt)))

  score_dt[,BSS_ex := (clim_BS_ex - BS_ex)/clim_BS_ex ]

  #deal with divisions by 0:
  score_dt[clim_BS_ex == 0 & BS_ex == 0, BSS_ex := 0] # when both are perfect, skill score should be 0
  score_dt[clim_BS_ex == 0 & BS_ex > 0, BSS_ex := -1] # set to something negative (capped at -1), when climatology predicts perfectly and the forecast does not
  #(should actually -Inf, but that's bad for plotting).
  return(score_dt)
}


#############################################################
############# Ensemble Forecast Scores ######################
#############################################################
# data tables with ensemble forecasts contain forecasts for real-valued observations.
# They may contain a column 'member', and can contain multiple predictions for each space-time coordinate, namely one prediction per member.
# They are not required to contain multiple members (!), so if you have a data table that contains a single prediction (e.g. the mean of an ensemble),
# you can compute the squared error by using MSE functions.
# The typical data table dropped into these functions should have (some of) the following columns:
# lon   lat   month   year    member    system    lead_time   fc    obs
# There are 5 different sets of columns that require different treatment: grouping variables, pool-variables, the member-column, forecasts and observations.
# - grouping variables generally provide the levels for which you want to evaluate the score separately. E.g. if these contain lon,lat, and month,
#   you'll get an average score for each month and grid point.
# - pool-variables tell you pool which columns is averaged. So if you calculate the MSE and your pool-variable is just year, then the MSE is averaged pool all years in the
#   data table. However, if the pool-variables are year and location, then the MSE is averaged over all years and locations.
# - the optional member column specifies the ensemble member.
# It is absolutely crucial that the data table unique(dt[,.(grouping variables, pool-variables,member column)]) has the same number of entries as the original data.table!!!
# Otherwise, your data contains multiple forecasts/observations for the same coordinate, making it impossible to calculate a score.


#' Function for calculating coefficients of predictive ability (CPAs) of ensemble mean forecasts stored in long data tables:
#'
#' Can also handle point forecasts.
#' Warning: This metric always needs several years of data since the ranks on which it is based are calculated across multi-year samples.
#' @param dt Data table containing the predictions.
#' @param f column name of the prediction.
#' @param o column name of the observations.
#' @param by column names of grouping variables, all of which need to be columns in dt. A separate CPA is computed for each value of the grouping variables.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param mem Number of column containing the number of the ensemble member.
#' @param pool column name(s) for the variable(s) along which is averaged. Needs to contain 'year' per warning above.
#' @param dim.check Logical. If True, a simple test whether the dimensions match up is conducted:
#' The data table should only have one row for each level of c(by,pool,mem)
#'
#' @export
#' @importFrom stats cov na.omit

CPA = function(dt, f, o = 'obs',
               by = by_cols_ens_fc_score(dt),
               pool = 'year',
               mem = 'member',
               dim.check = TRUE)
{
  # for devtools::check:
  fc_mean = fc_midrank = obs_class = obs_midrank = NULL

  by = intersect(by,names(dt))
  pool = intersect(pool,names(dt))
  mem = intersect(mem,names(dt))

  checks_ens_fc_score()

  # get forecast mean (= mean over all ensemble members)
  dt[, fc_mean:=mean(get(f), na.rm=T), by=c(by,pool)]

  # combine data into a single DT and remove rows with missing data
  dt = stats::na.omit(dt[, .SD, .SDcols=c("fc_mean",o,by,pool)])

  # calculate the CPA
  dt[, fc_midrank:=frank(fc_mean,ties.method="average"), by=by]
  dt[, obs_class:=frank(get(o),ties.method="dense"), by=by]
  dt[, obs_midrank:=frank(get(o),ties.method="average"), by=by]
  CPA_dt = dt[, .(cpa=0.5*(1.+stats::cov(obs_class,fc_midrank)/stats::cov(obs_class,obs_midrank))), by=by]

  return(CPA_dt)
}


#' Taking CRPSs of ensemble forecasts stored in long data tables:
#'
#' @param dt Data table containing predictions and observations.
#' @param f column name of the forecasts. May not be called 'f'
#' @param o column name of the observations.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) over which is averaged. Typically just 'year'.
#' @param mem Name of the column identifying the ensemble member.
#' @param dim.check Logical. If True, a simple test whether the dimensions match up is conducted:
#' The data table should only have one row for each level of c(by,pool,mem)
#' @param ens_size_correction logical. If TRUE, the CRPS is corrected for sample size (see Ferro et al. 2008: 'On the effect of ensemble size on the discrete and continuous
#' ranked probability scores'). This is slower, but you should do it if you compare ensembles of different size.
#'
#' @export

CRPS = function(dt, f, o = "obs",
                by = by_cols_ens_fc_score(),
                pool = "year",
                mem = "member",
                dim.check = T,
                ens_size_correction = FALSE)
{
  by = intersect(by, names(dt))
  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]
  checks_ens_fc_score()

  if(!ens_size_correction)  ret_dt = dt[,.(CRPS = crps_aux(get(o),get(f))),by = c(by,pool)]
  if(ens_size_correction)  ret_dt = dt[,.(CRPS = crps_aux_esc(get(o),get(f))),by = c(by,pool)]

  ret_dt = ret_dt[, .(CRPS = mean(CRPS)), by = by]
  return(ret_dt)
}

#' Auxiliary function for calculating crps.
#' Mostly copy-paste from scoringRules::crps_edf. Adjusted to the data table format, where the observation is a vector of the same length as the ensemble forecast,
#' but is just repeated (which is why only y[1]) is used.
#' @param y vector of length m with m identical entries, the observation
#' @param dat vector of length m containing the m ensemble forecasts

crps_aux = function(y,dat)
{

  c_1n <- 1/length(dat)
  x <- sort(dat)
  a <- seq.int(0.5 * c_1n, 1 - 0.5 * c_1n, length.out = length(dat))
  ret <- 2 * c_1n * sum(((y[1] < x) - a) * (x - y[1]))
  return(ret)
}

#' Auxiliary function for calculating crps with ensemble size correction by Ferro et al. 2008.
#' Mostly copy-paste from scoringRules::crps_edf. Adjusted to the data table format, where the observation is a vector of the same length as the ensemble forecast,
#' but is just repeated (which is why only y[1]) is used.
#' @param y vector of length m with m identical entries, the observation
#' @param dat vector of length m containing the m ensemble forecasts

crps_aux_esc = function(y,dat)
{
  c_1n <- 1/length(dat)
  x <- sort(dat)
  a <- seq.int(0.5 * c_1n, 1 - 0.5 * c_1n, length.out = length(dat))
  ret <- 2 * c_1n * sum(((y[1] < x) - a) * (x - y[1]))

  #ensemble size correction:
  ens_size = length(dat)
  mean_dist_xx = mean(stats::dist(dat))
  ret = ret - mean_dist_xx/(2*ens_size)
  return(ret)
}


#' Function for taking CRPS skill scores of ensemble forecasts stored in long data tables:
#'
#' Warning: The skill score needs a climatological forecast as reference. This is so far always based on the leave-one-year-out climatology.
#' @param dt Data table containing predictions and observations.
#' @param f column name of the prediction.
#' @param o column name of the observations.
#' @param by column names of grouping variables, all of which need to be columns in dt. A separate CRPS is computed for each value of the grouping variables.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged. Needs to contain 'year' since the reference climatology forecast is leave-one-year-out.
#' @param ... passed on to CRPS_ens_fc, in particular mem and dim.check
#'
#' @export

CRPSS = function(dt,f,
                 o = 'obs',
                 by = by_cols_ens_fc_score(),
                 pool = c('year'),...)
{
  # for devtools::check:
  clim_CRPS = NULL

  by = intersect(by,names(dt))

  if(!('year' %in% pool)) stop('skill scores are with respect to leave-one-year-out climatology, so the pool-argument must contain "year".')

  # get climatological loyo-prediction
  obs_dt = unique(dt[,.SD,.SDcols = c(o,obs_dimvars(dt))])
  obs_by = intersect(by,obs_dimvars(dt))
  climatology_prediction = climatology_ens_forecast(obs_dt = obs_dt,
                                                    by = obs_by)

  setnames(climatology_prediction,'obs','clim')

  climatology_prediction = merge(climatology_prediction,obs_dt,by = c(obs_by,'year'))

  climatology_CRPS = CRPS(dt = climatology_prediction,
                                 f = 'clim',
                                 o = o,
                                 by = obs_by)

  setnames(climatology_CRPS,'CRPS','clim_CRPS')

  CRPS_dt = CRPS(dt = dt,
                        f = f,
                        o = o,
                        by = by,
                        pool = pool,...)

  CRPS_dt = merge(CRPS_dt,climatology_CRPS,by = by)
  CRPS_dt[,CRPSS := (clim_CRPS - CRPS)/clim_CRPS]

  return(CRPS_dt)

}


#' Taking MSEs of ensemble forecasts stored in long data tables. Can also handle point forecast
#'
#' @param dt Data table containing the predictions.
#' @param f column name of the prediction.
#' @param o column name of the observations.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param mem Name of the column identifying the ensemble member. Only used if check_dimension is TRUE. Is NULL for a point forecast.
#' @param dim.check Logical. If True, a simple test whether the dimensions match up is conducted:
#' The data table should only have one row for each level of c(by,pool,mem)
#' @export


MSE = function(dt,
               f, o = 'obs',
               by = by_cols_ens_fc_score(),
               pool = 'year',
               mem = 'member',
               dim.check = T)
{
  # for devtools::check:
  fc_mean = NULL

  by = intersect(by,names(dt))
  pool = intersect(pool,names(dt))
  mem = intersect(mem,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  #checks:
  checks_ens_fc_score()


  # get forecast mean (= mean over all ensemble members)
  dt_new = copy(dt)[,fc_mean := mean(unlist(.SD),na.rm = T),.SDcols = f,by = c(by,pool)]
  #IMPORTANT: in the line above, why do we use .SD and .SDcols rather than simply get(f)?
  # using mean(get(f)) usually works, BUT it doesn't when the forecast column is in fact called 'f',
  # so the function would crash when its called with f = 'f'. This is not so important for the forecast column,
  # but very important for the obs column, which is called 'obs' as default!

  # take MSE:
  MSE_dt = dt_new[,.(MSE = mean((fc_mean - unlist(.SD))^2,na.rm = T)),.SDcols = o,by = by]
  return(MSE_dt)
}


#' Function for taking MSE skill scores of ensemble forecasts stored in long data tables:
#'
#' Can also handle point forecasts.
#' Warning: The skill score needs a climatological forecast as reference. This is so far always based on the leave-one-year-out climatology.
#' @param dt Data table containing the predictions.
#' @param f column name of the prediction.
#' @param o column name of the observations.
#' @param by column names of grouping variables, all of which need to be columns in dt. A separate MSE is computed for each value of the grouping variables.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged. Needs to contain 'year' since the reference climatology forecast is leave-one-year-out.
#' @param ... passed on to MSE
#'
#' @export

MSES = function(dt,f,
                o = 'obs',
                by = by_cols_ens_fc_score(),
                pool = c('year'),...)
{
  # for devtools::check:
  clim_MSE = NULL

  by = intersect(by,names(dt))
  if(!('year' %in% pool)) stop('skill scores are with respect to leave-one-year-out climatology, so your pool must contain "year".')

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  # get climatological loyo-prediction
  obs_dt = unique(dt[,.SD,.SDcols = c(o,obs_dimvars(dt))])
  obs_by = intersect(by,obs_dimvars(dt))
  climatology_prediction = climatology_ens_forecast(obs_dt = obs_dt,
                                                    by = obs_by)
  setnames(climatology_prediction,o,'clim')

  climatology_prediction = merge(climatology_prediction,obs_dt,by = c(obs_by,'year'))

  climatology_MSE = MSE(dt = climatology_prediction,
                           f = 'clim',
                           o = o,
                           by = obs_by)

  setnames(climatology_MSE,'MSE','clim_MSE')

  MSE_dt = MSE(dt = dt,
                  f = f,
                  o = o,
                  by = by,
                  pool = pool,...)

  MSE_dt = merge(MSE_dt,climatology_MSE, by = intersect(names(MSE_dt),names(climatology_MSE)))
  MSE_dt[,MSES := (clim_MSE - MSE)/clim_MSE]

  return(MSE_dt)
}



#' Function for calculating Pearson correlation coefficients (PCCs) of ensemble mean forecasts stored in long data tables:
#'
#' Can also handle point forecasts.
#' Warning: This metric always needs several years of data since the means and standard deviations are calculated across time.
#' @param dt Data table containing the predictions.
#' @param f column name of the prediction.
#' @param o column name of the observations.
#' @param by column names of grouping variables, all of which need to be columns in dt. A separate PCC is computed for each value of the grouping variables.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged. Needs to contain 'year' per warning above.
#' @param mem Name of the column identifying the ensemble member. Only used if check_dimension is TRUE. Is NULL for a point forecast.
#' @param dim.check Logical. If True, a simple test whether the dimensions match up is conducted:
#' The data table should only have one row for each level of c(by,pool,mem)
#'
#' @export
#' @importFrom stats cor

PCC = function(dt, f,
               o = 'obs',
               by = by_cols_ens_fc_score(dt),
               pool = 'year',
               mem = 'member',
               dim.check = TRUE)
{
  # for devtools::check:
  fc_mean = NULL

  by = intersect(by,names(dt))
  pool = intersect(pool,names(dt))
  mem = intersect(mem,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  # checks:
  checks_ens_fc_score()


  # get forecast mean (= mean over all ensemble members)
  dt[, fc_mean:=mean(get(f),na.rm = T), by=c(by,pool)]

  # calculate correlation coefficient
  dt = dt[, .SD, .SDcols=c("fc_mean",o,by,pool)]
  PCC_dt = dt[, .(rho=stats::cor(fc_mean,get(o),use="na.or.complete")), by=by]

  return(PCC_dt)
}



############################################
####### Scores for tercile forecasts #######
############################################



#######################


#' Compute the Hit score
#'
#' This score is suitable for tercile category forecasts. This score is the frequency at which the highest probability category actually
#' happens. The function also provides the frequency at which the second-highest probability category, and lowest probability category,
#' actually happens.
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export

HS = function(dt,f = c('below','normal','above'),
              o = 'tercile_cat',
              by = by_cols_terc_fc_score(),
              pool = 'year',
              dim.check = TRUE)
{
  # for devtools::check:
  HS_min = HS_mid = HS_max = max_cat = min_cat = hit = hit3 = NULL

  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Hit score:
  ddt = copy(dt)
  ddt = ddt[,max_cat:=c(-1,0,1)[max.col(ddt[,mget(f)])]] #max.col breaks ties at random
  ddt = ddt[,min_cat:=c(-1,0,1)[max.col(-1*ddt[,mget(f)])]]
  ddt = ddt[,hit:=as.numeric(get(o)==max_cat)]
  ddt = ddt[,hit3:=as.numeric(get(o)==min_cat)]
  HS_dt = ddt[,.(HS_max = mean(hit), HS_min = mean(hit3)),by = by]
  HS_dt = HS_dt[,HS_mid:=1-HS_max-HS_min]
  return(HS_dt)
}

#' Compute the Hit skill score
#'
#' This score is suitable for tercile category forecasts. The skill score is the difference between the hit scores
#' for the categories with the highest and lowest probabilities.
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export

HSS = function(dt,f = c('below','normal','above'),
               o = 'tercile_cat',
               by = by_cols_terc_fc_score(),
               pool = 'year',
               dim.check = TRUE)
{
  # for devtools::check:
  HS_max = HS_min = NULL

  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Hit skill score:

  HS_dt = HS(dt,f,o,by,pool)
  HSS_dt = HS_dt[,.(HSS = HS_max-HS_min),by = by]
  return(HSS_dt)
}


#' Compute the effective interest rate
#'
#' This score is suitable for tercile category forecasts. Using log2 for now (?). According to Mason, the averaging here
#' should be over many years at a single locations and for discrete time-periods (so Mason prefers to take the average after
#' is one wants to average over different locations, but I keep it like this for now).
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export

EIR = function(dt,f = c('below','normal','above'),
               o = 'tercile_cat',
               by = by_cols_terc_fc_score(),
               pool = 'year',
               dim.check = TRUE)
{
  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Ignorance skill score:

  EIR_dt = dt[,.(EIR =2^(-log2(1/3) + mean(indicator_times_value_aux((get(o) == -1),log2(get(f[1]))) +
                                             indicator_times_value_aux((get(o) == 0),log2(get(f[2]))) +
                                             indicator_times_value_aux((get(o) == 1),log2(get(f[3])))))-1),by = by]

  return(EIR_dt)
}


#' Auxiliary function for multiplying two numbers such that 0 x infty is 0. Needed for the ignorance score: 0log(0) should be 0.
#' @param indicator logical input vector
#' @param value numeric input vector
#' @return indicator x value with 0*infty = 0

indicator_times_value_aux = function(indicator,value)
{
  ret_vec = rep(0, length(indicator))
  ret_vec[indicator] = value[indicator]
  return(ret_vec)
}

#' Compute the Ignorance score
#'
#' This score is suitable for tercile category forecasts. Using log2 for now (?).
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export

IGS = function(dt,f = c('below','normal','above'),
                o = 'tercile_cat',
                by = by_cols_terc_fc_score(),
                pool = 'year',
                dim.check = TRUE)
{
  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Ignorance score:

  IGS_dt = dt[,.(IGS = - mean((indicator_times_value_aux((get(o) == -1),log2(get(f[1]))) +
                                 indicator_times_value_aux((get(o) == 0),log2(get(f[2]))) +
                                 indicator_times_value_aux((get(o) == 1),log2(get(f[3])))))),
              by = by]

  return(IGS_dt)
}




#' Compute the Ignorance Skill score
#'
#' This score is suitable for tercile category forecasts. Using log2 for now (?). This is the "usual" skill score
#' (not the effective interest rate).
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export

IGSS = function(dt,f = c('below','normal','above'),
                 o = 'tercile_cat',
                 by = by_cols_terc_fc_score(),
                 pool = 'year',
                 dim.check = TRUE)
{
  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Ignorance score:

  IGSS_dt = dt[,.(IGSS = 1 - mean((indicator_times_value_aux((get(o) == -1),log2(get(f[1]))) +
                                     indicator_times_value_aux((get(o) == 0),log2(get(f[2]))) +
                                     indicator_times_value_aux((get(o) == 1),log2(get(f[3])))))/log2(1/3)),
               by = by]

  return(IGSS_dt)
}



#' Compute the Multicategory Brier Skill score
#'
#' This score is suitable for tercile category forecasts.
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export

MBS = function(dt,f = c('below','normal','above'),
               o = 'tercile_cat',
               by = by_cols_terc_fc_score(),
               pool = 'year',
               dim.check = TRUE)
{
  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Multicategory Brier skill score:

  MBSS_dt = dt[,.(MBS = 3/2 * (2/3 - mean((get(f[1]) - (get(o) == -1))^2 + (get(f[2]) - (get(o) == 0))^2 + (get(f[3]) - (get(o) == 1))^2))),by = by]
  return(MBSS_dt)
}



#' Calculate the area under curve (AUC) or ROC-score from a vector of probabilities and corresponding observations
#' Formula (1a) from Mason&2018 is used in the calculation, corresponding to trapezoidal interpolation.
#' Mostly auxiliary function for the ROCS function, but also used in the ROC-diagram function, where the AUC is added to the diagrams.
#'
#' @param probs vector with probabilities (between 0 and 1)
#' @param obs vector with categorical observations
#'
#' @export

roc_score_vec = function(probs,obs)
{
  # for devtools::check():
  prob = countzeros = countzeros2 = NULL
  #use data tables fast order:
  temp = data.table(prob = probs,obs = obs)
  setorder(temp,prob,obs) # sort by probability. For multiple entries with equal probabilities, sort the ones with obs == TRUE last.

  n1 = temp[(obs),.N]
  n0 = temp[!(obs),.N]
  temp[,countzeros := cumsum(!obs)] # counts for each entry how many zero-observations have happened previously, including the ones with the same probability as the entry.
  temp[,countzeros2 := 0.5*cumsum(!obs),by = prob] # counts for each entry how many zero-observations have happened with the same probability as the entry.

  ROCscore = temp[(obs),sum(countzeros - countzeros2)/(n1 * n0)]
  return(ROCscore)
}


#' Compute the ROC-score/Area Under Curve(AUC)
#'
#' This score is not proper, but can be used to assess the resolution of a tercile forecast.
#'
#' The ROC score requires more datapoints to be robust than e.g. the ignorance or Brier score. Therefore the default is to pool the data in space and only calculate one score per season.
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export


ROCS = function(dt,f = c('below','normal','above'),
                o = 'tercile_cat',
                by = by_cols_terc_fc_score_sp(dt),
                pool = c('year',space_dimvars(dt)),
                dim.check = TRUE)
{
  # for devtools::check:
  ROC_normal = ROC_below = NULL

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # ROC score:
  res_above = dt[,.(ROC_above = roc_score_vec(get(f[3]),get(o) == 1)),by = by]
  res_normal = dt[,.(ROC_normal = roc_score_vec(get(f[2]),get(o) == 0)),by = by]
  res_below = dt[,.(ROC_below = roc_score_vec(get(f[1]),get(o) == -1)),by = by]

  res = res_above[,ROC_normal := res_normal[,ROC_normal]]
  res[,ROC_below := res_below[,ROC_below]]
  return(res)
}

#' Compute the Ranked Probability score
#'
#' This score is suitable for tercile category forecasts.
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export

RPS = function(dt,f = c('below','normal','above'),
                o = 'tercile_cat',
                by = by_cols_terc_fc_score(),
                pool = 'year',
                dim.check = TRUE)
{
  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Ranked Probability score:

  RPS_dt = dt[,.(RPS = mean((get(f[1]) - (get(o) == -1))^2  + (get(f[3]) - (get(o) == 1))^2)),by = by]
  return(RPS_dt)
}


#' Compute the Ranked Probability skill score
#'
#' This score is suitable for tercile category forecasts.
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export


RPSS = function(dt,f = c('below','normal','above'),
               o = 'tercile_cat',
               by = by_cols_terc_fc_score(),
               pool = 'year',
               dim.check = TRUE)
{
  # for devtools::check:
  RPS_clim = NULL

  by = intersect(by,names(dt))

  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  # Ranked Probability skill score:

  #RPS_dt = RPS(dt,f,o,by,pool)
  RPS_dt = dt[,.(RPS = mean((get(f[1]) - (get(o) == -1))^2  + (get(f[3]) - (get(o) == 1))^2),
                     RPS_clim = mean((1/3 - (get(o) == -1))^2  + (1/3 - (get(o) == 1))^2)),by = by]
  RPSS_dt = RPS_dt[,RPSS := 1-RPS/RPS_clim]

  return(RPSS_dt)
}

#' Compute the slope of the reliability curve
#'
#' Values below 1 indicate a lack of resolution or overconfidence, 1 is perfect, above means underconfident.
#' This score requires more datapoints to be robust than e.g. the ignorance or Brier score. Therefore the default is to pool the data in space and only calculate one score per season.
#'
#' @param dt Data table containing the predictions.
#' @param f column names of the prediction.
#' @param o column name of the observations (either in obs_dt, or in dt if obs_dt = NULL). The observation column needs to
#' contain -1 if it falls into the first category (corresponding to fcs[1]), 0 for the second and 1 for the third category.
#' @param by column names of grouping variables, all of which need to be columns in dt.
#' Default is to group by all instances of month, season, lon, lat, system and lead_time that are columns in dt.
#' @param pool column name(s) for the variable(s) along which is averaged, typically just 'year'.
#' @param dim.check Logical. If TRUE, the function tests whether the data table contains only one row per coordinate-level, as should be the case.
#' @export


SRC = function(dt,f = c('below','normal','above'),
                o = 'tercile_cat',
                by = by_cols_terc_fc_score_sp(dt),
                pool = c('year',space_dimvars(dt)),
                dim.check = TRUE)
{
  # for devtools::check:
  SRC_normal = SRC_below = NULL


  dt = dt[!is.na(get(o)) & !is.na(get(f[1]))]

  checks_terc_fc_score()

  rdv_wrapper = function(discrete_probs, obs)
  {
    ret_val = suppressWarnings(rel_diag_vec(discrete_probs, obs, slope_only = TRUE))
    return(ret_val)
  }


  # score:
  res_above = dt[,.(SRC_above = rdv_wrapper(get(f[3]),get(o) == 1)),by = by]
  res_normal = dt[,.(SRC_normal = rdv_wrapper(get(f[2]),get(o) == 0)),by = by]
  res_below = dt[,.(SRC_below = rdv_wrapper(get(f[1]),get(o) == -1)),by = by]

  res = res_above[,SRC_normal := res_normal[,SRC_normal]]
  res[,SRC_below := res_below[,SRC_below]]
  return(res)
}

