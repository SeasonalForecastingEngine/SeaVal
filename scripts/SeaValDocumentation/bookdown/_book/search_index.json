[["index.html", "Tutorial for the SeaVal package 1 Getting Started 1.1 Installation 1.2 examples of data.table syntax", " Tutorial for the SeaVal package Claudio Heinrich 1 Getting Started This tutorial gives a short introduction how to use the R-package SeaVal for seasonal validation, which is currently developed at NR and made available via Github. The package provides a toolkit to evaluate predictions, tailored to specific needs of ICPAC. SeaVal relies on R data tables (available with the R package data.table). Data tables are more flexible and memory efficient data frames, and simplify many operations that are frequently required when working with weather- and climate data. An introduction to data tables can be found here: https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html. The package SeaVal allows to import netcdf-files as data tables. Moreover, it contains functionality for generating a variety of diagnostic plots, and provides various tools for forecast evaluation. 1.1 Installation In order to get started with the package, you first need to install the packages devtools (if you don't have it already), which allows installing packages from Github directly: install.packages(&#39;devtools&#39;) Now you should be able to install the SeaVal-package using the following command devtools::install_github(&#39;SeasonalForecastingEngine/SeaVal&#39;) This installs SeaVal and all packages it depends on. This may take a while, especially if you didn't have some of the larger dependency packages installed, such as data.table or ggplot2. Also, it is possible that you'll get a message like this: These packages have more recent versions available. It is recommended to update all of them. Which would you like to update? 1: All 2: CRAN packages only 3: None ... In that case just type '1' for all. If this completes without an error, the setup is complete and you're good to go. From here on out, all you have to do is load SeaVal: library(SeaVal) ## Loading required package: data.table ## Loading required package: ForecastTools Especially in the early development phase, it is important to occasionally update the SeaVal package. To this end you should run the two commands devtools::install_github(&#39;SeasonalForecastingEngine/ForecastTools&#39;) devtools::install_github(&#39;SeasonalForecastingEngine/SeaVal&#39;) 1.2 examples of data.table syntax Here, we show with some examples how to perform basic operations on data tables. A short but comprehensive introduction to data.tables syntax can be found here: https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html. The SeaVal package comes with a few example data sets, for example monthly mean precipitation over the GHA region for the OND season provided by CHIRPS: data(&quot;chirps_monthly&quot;) print(chirps_monthly) ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 1.9301587 10 1981 -1 ## 2: 22.0 -11.5 2.1351602 10 1981 -1 ## 3: 22.0 -11.0 2.7692883 10 1981 -1 ## 4: 22.0 -10.5 3.9201619 10 1981 0 ## 5: 22.0 -10.0 4.8720656 10 1981 1 ## --- ## 418076: 51.5 21.0 0.2404348 12 2020 -1 ## 418077: 51.5 21.5 0.2184058 12 2020 -1 ## 418078: 51.5 22.0 0.2053623 12 2020 -1 ## 418079: 51.5 22.5 0.1615942 12 2020 -1 ## 418080: 51.5 23.0 0.1387682 12 2020 -1 We can look at a short description of the dataset like this: ?chirps_monthly We'll now go over a few basic commands for handling this sort of data. chirps_monthly is a data_table, which is an enhanced data frame. The most fundamental operations include subsetting, performing calculations on columns and aggregation or grouping for calculations. Examples for subsetting are chirps_monthly[month == 10] # extract the data for October ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 1.930158724 10 1981 -1 ## 2: 22.0 -11.5 2.135160243 10 1981 -1 ## 3: 22.0 -11.0 2.769288266 10 1981 -1 ## 4: 22.0 -10.5 3.920161870 10 1981 0 ## 5: 22.0 -10.0 4.872065602 10 1981 1 ## --- ## 139356: 51.5 21.0 0.033333333 10 2020 -1 ## 139357: 51.5 21.5 0.033333333 10 2020 0 ## 139358: 51.5 22.0 0.032608688 10 2020 -1 ## 139359: 51.5 22.5 0.001594238 10 2020 -1 ## 139360: 51.5 23.0 0.000000000 10 2020 -1 chirps_monthly[year %between% c(1990,1999)] # extract the data for 1990 - 1999 ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 3.1261905 10 1990 1 ## 2: 22.0 -11.5 3.5520651 10 1990 1 ## 3: 22.0 -11.0 3.9256340 10 1990 1 ## 4: 22.0 -10.5 4.4879379 10 1990 1 ## 5: 22.0 -10.0 4.4143639 10 1990 0 ## --- ## 104516: 51.5 21.0 0.2565218 12 1999 0 ## 104517: 51.5 21.5 0.2427537 12 1999 1 ## 104518: 51.5 22.0 0.2171015 12 1999 1 ## 104519: 51.5 22.5 0.2000000 12 1999 1 ## 104520: 51.5 23.0 0.1981884 12 1999 1 chirps_monthly[1000:2000] # extract rows 1000 - 2000 ## lon lat prec month year terc_cat ## 1: 29 -9.5 1.74899961 10 1981 0 ## 2: 29 -9.0 1.44546648 10 1981 -1 ## 3: 29 -8.5 1.45933371 10 1981 -1 ## 4: 29 -8.0 1.52153314 10 1981 -1 ## 5: 29 -7.5 1.35046587 10 1981 -1 ## --- ## 997: 36 -8.5 0.49439943 10 1981 0 ## 998: 36 -8.0 0.31293185 10 1981 0 ## 999: 36 -7.5 0.06879925 10 1981 -1 ## 1000: 36 -7.0 0.01446661 10 1981 -1 ## 1001: 36 -6.5 0.04019988 10 1981 0 chirps_monthly[month == 10][lon &gt; 30][terc_cat == 0] #chained subsetting: get all October values at locations with longitude &gt;30 that had normal rainfall (terc_cat == 0) ## lon lat prec month year terc_cat ## 1: 30.5 -10.5 0.67720063 10 1981 0 ## 2: 30.5 -10.0 0.78526832 10 1981 0 ## 3: 30.5 -9.5 1.03640187 10 1981 0 ## 4: 30.5 -9.0 0.96939957 10 1981 0 ## 5: 30.5 -8.5 0.52219994 10 1981 0 ## --- ## 32909: 51.0 20.0 0.06666667 10 2020 0 ## 32910: 51.0 21.5 0.03333333 10 2020 0 ## 32911: 51.5 19.5 0.06666667 10 2020 0 ## 32912: 51.5 20.0 0.06666667 10 2020 0 ## 32913: 51.5 21.5 0.03333333 10 2020 0 chirps_monthly[month == 10 &amp; lon &gt; 30 &amp; terc_cat == 0] # different syntax, same effect. ## lon lat prec month year terc_cat ## 1: 30.5 -10.5 0.67720063 10 1981 0 ## 2: 30.5 -10.0 0.78526832 10 1981 0 ## 3: 30.5 -9.5 1.03640187 10 1981 0 ## 4: 30.5 -9.0 0.96939957 10 1981 0 ## 5: 30.5 -8.5 0.52219994 10 1981 0 ## --- ## 32909: 51.0 20.0 0.06666667 10 2020 0 ## 32910: 51.0 21.5 0.03333333 10 2020 0 ## 32911: 51.5 19.5 0.06666667 10 2020 0 ## 32912: 51.5 20.0 0.06666667 10 2020 0 ## 32913: 51.5 21.5 0.03333333 10 2020 0 We can subset either by logical expressions or by row indices (third example above). Subsetting always returns a data table, e.g. chirps_monthly[1] returns a one-row data table containing the first row of chirps_monthly. Next, let's look at examples for operations on columns: chirps_monthly[,mean(prec)] # get the mean precipitation (over all locations, months, years) ## [1] 1.995215 chirps_monthly[,mean_prec := mean(prec)] # create a new column in the data table containing the mean chirps_monthly[,prec := 30*prec] # transform precipitation from unit mm/day to mm (per month) Note in all cases the ',' after '[' which tells data table that you're doing an operation rather than trying to subset. We can also put things together and subset and operate simultaneously: chirps_monthly[month == 10 , mean(prec)] # get the mean precipitation for October (over all locations, years) ## [1] 66.30285 (Note that the mean is much larger now because we changed units above...) Finally, we can perform operations over aggregated groups: dt_new = chirps_monthly[, mean(prec),by = .(lon,lat,month)] print(dt_new) ## lon lat month V1 ## 1: 22.0 -12.0 10 84.507765 ## 2: 22.0 -11.5 10 92.716755 ## 3: 22.0 -11.0 10 104.027108 ## 4: 22.0 -10.5 10 116.425850 ## 5: 22.0 -10.0 10 128.969907 ## --- ## 10448: 51.5 21.0 12 7.679457 ## 10449: 51.5 21.5 12 7.247609 ## 10450: 51.5 22.0 12 6.454131 ## 10451: 51.5 22.5 12 5.612391 ## 10452: 51.5 23.0 12 5.103941 Here, the 'by' command (after the second comma) tells data table to perform the operation (mean) for each instance of lon, lat, and month separately. As a result, the mean is taken only over all years and we obtain the monthly local climatology. As we can see, the output is a data table containing all columns in by and a column named V1 containing the output of the operation. That's of course a bit impractical. But it's easy to rename columns: setnames(dt_new,&#39;V1&#39;,&#39;clim&#39;) # take the data table from above and rename column &#39;V1&#39; into &#39;clim&#39; It's also possible to name the column direcly while dt_new is created, like this: dt_new = chirps_monthly[,.(clim = mean(prec)),by = .(lon,lat,month)] # same as above, but with simultaneously setting the name of the new column This can again be combined with subsetting: dt_new = chirps_monthly[year %in% 1990:2020, .(clim = mean(prec)), by = .(lon,lat,month)] # same as above, but with additional subsetting: computes climatology based on the years 1990-2020 only. In the examples above we create a new data table containing the climatology. If we instead want to add the climatology as a new column to chirps_monthly directly, we can again use the := operator: chirps_monthly[,clim := mean(prec), by = .(lon,lat,month)] # add the climatology column directly into chirps_monthly. This showcases some of the main functionalities and syntax of the data.table package. As mentioned above, it is strongly recommended to have a look at https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html, which introduces many more commands and properly explains the logic underlying data.tables syntax. We'll finish this section by an example where we compute the MSE for raw ecmwf forecasts: data(&quot;chirps_monthly&quot;) # reload data to reverse the changes made in the examples above. data(&quot;ecmwf_monthly&quot;) # get example hindcasts from ecmwf print(ecmwf_monthly) ## lon lat year month prec member below normal above ## 1: 22 13.0 1993 10 0.0118023199 1 0.60 0.20 0.20 ## 2: 22 13.0 1993 10 0.0257743523 2 0.60 0.20 0.20 ## 3: 22 13.0 1993 10 0.0008075972 3 0.60 0.20 0.20 ## 4: 22 13.0 1993 10 0.1190863216 4 0.60 0.20 0.20 ## 5: 22 13.0 1993 10 0.0002728474 5 0.60 0.20 0.20 ## --- ## 868556: 51 11.5 2020 12 0.8410410288 1 0.36 0.28 0.36 ## 868557: 51 11.5 2020 12 0.7719732821 2 0.36 0.28 0.36 ## 868558: 51 11.5 2020 12 1.4691380784 3 0.36 0.28 0.36 ## 868559: 51 11.5 2020 12 1.2364573109 4 0.36 0.28 0.36 ## 868560: 51 11.5 2020 12 1.2289135981 5 0.36 0.28 0.36 # merge observations and predictions into a single data table: setnames(chirps_monthly,&#39;prec&#39;,&#39;obs&#39;) # rename the &#39;prec&#39; column in the observation data table to &#39;obs&#39; in order to avoid name clashes since the column in ecmwf_monthly containing the predictions for precip is also named &#39;prec&#39; dt = merge(ecmwf_monthly,chirps_monthly, by = c(&#39;lon&#39;,&#39;lat&#39;,&#39;year&#39;,&#39;month&#39;)) # merge the data. print(dt) ## lon lat year month prec member below normal above obs ## 1: 22 13.0 1993 10 0.0118023199 1 0.60 0.20 0.20 0.3490475 ## 2: 22 13.0 1993 10 0.0257743523 2 0.60 0.20 0.20 0.3490475 ## 3: 22 13.0 1993 10 0.0008075972 3 0.60 0.20 0.20 0.3490475 ## 4: 22 13.0 1993 10 0.1190863216 4 0.60 0.20 0.20 0.3490475 ## 5: 22 13.0 1993 10 0.0002728474 5 0.60 0.20 0.20 0.3490475 ## --- ## 868556: 51 11.5 2020 12 0.8410410288 1 0.36 0.28 0.36 0.5262209 ## 868557: 51 11.5 2020 12 0.7719732821 2 0.36 0.28 0.36 0.5262209 ## 868558: 51 11.5 2020 12 1.4691380784 3 0.36 0.28 0.36 0.5262209 ## 868559: 51 11.5 2020 12 1.2364573109 4 0.36 0.28 0.36 0.5262209 ## 868560: 51 11.5 2020 12 1.2289135981 5 0.36 0.28 0.36 0.5262209 ## terc_cat ## 1: 0 ## 2: 0 ## 3: 0 ## 4: 0 ## 5: 0 ## --- ## 868556: 0 ## 868557: 0 ## 868558: 0 ## 868559: 0 ## 868560: 0 dt[,ens_mean := mean(prec),by = .(lon,lat,year,month)] # get the ensemble mean, essentially group by all other dimension variables mse_dt = dt[,.(mse = mean((prec-obs)^2)), by = .(lon,lat,month)] # create a new data.table containing the mse by location and month print(mse_dt) ## lon lat month mse ## 1: 22.0 13.0 10 7.263275e-01 ## 2: 22.0 13.0 11 2.330523e-03 ## 3: 22.0 13.0 12 4.717186e-05 ## 4: 22.5 12.5 10 1.100971e+00 ## 5: 22.5 12.5 11 8.114504e-03 ## --- ## 6200: 51.0 11.0 11 2.520367e+00 ## 6201: 51.0 11.0 12 1.086045e+00 ## 6202: 51.0 11.5 10 1.304131e+00 ## 6203: 51.0 11.5 11 3.431530e+00 ## 6204: 51.0 11.5 12 1.362873e+00 ggplot_dt(mse_dt[month == 10],&#39;mse&#39;,rr = c(-10,10) ) # plot mse for October The function ggplot_dt is used to create spatial plots from data stored in data tables. In the next section we will showcase how this function works and how the plots can be manipulated. "],["plotting.html", "2 Plotting 2.1 Plotting values for selected countries 2.2 More plotting options", " 2 Plotting The function ggplot_dt takes a data table containing two columns named lon and lat that should specify a regular longitude-latitude grid, as well as some data to use for coloring the map. An easy example is the following data(&quot;chirps_monthly&quot;) dt = copy(chirps_monthly) # to manipulate the data table: chirps_monthly has locked binding dt2020 = dt[year == 2020 &amp; month == 10] # reduce the observed precipitation data to a single time slice, namely October 2020 print(dt2020) ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 2.981750252 10 2020 0 ## 2: 22.0 -11.5 3.382063644 10 2020 0 ## 3: 22.0 -11.0 3.250394658 10 2020 0 ## 4: 22.0 -10.5 3.065396443 10 2020 -1 ## 5: 22.0 -10.0 3.416906726 10 2020 -1 ## --- ## 3480: 51.5 21.0 0.033333333 10 2020 -1 ## 3481: 51.5 21.5 0.033333333 10 2020 0 ## 3482: 51.5 22.0 0.032608688 10 2020 -1 ## 3483: 51.5 22.5 0.001594238 10 2020 -1 ## 3484: 51.5 23.0 0.000000000 10 2020 -1 ggplot_dt(dt2020,&#39;prec&#39;) As we can see, the color scale here makes no sense (blue meaning no precipitation) and we'll talk about that in a second. But let's start at the base functionality. ggplot_dt requires two arguments, the first one being a data table containing the data, and the second one is the name of the column that contains the data you want to plot. This defaults to the third column in the data table (often your data table will start with lon, lat, and the third column is what you want to plot). So in the example above, ggplot_dt(dt) would have led to the same result, because 'obs' is the third column in dt. The plotting window is determined by the data. If you have data covering the entire earth, the entire earth would be plotted. As a consequence, we can restrict the plotted region by subsetting the data table: dt_sub = dt2020[lon %between% c(28,43) &amp; lat %between% c(-12,1)] # a region containing Tanzania ggplot_dt(dt_sub) The function has further optional arguments (also recall that you can access the function documentation summarizing all of this by typing ?ggplot_dt): ggplot_dt(dt_sub,&#39;prec&#39;, mn = &#39;October 2020 precipitation&#39;, # add a title to the plot rr = c(1,10), # fix the limits of the color scale name = &#39;mm/day&#39;) # change the legend label In this example we set the lower limit of the color scale to 1 and the upper limit to 10. Note that the plot truncates the data at the ends of the color scale, so every pixel with precipitation of below 1mm/day is now shown in the same blue color. Setting the range of the color scale is particularly useful to force symmetry around 0, e.g. when plotting correlations or anomalies: dt[,clim := mean(prec), by = .(lon,lat,month)] # add a climatology column dt[,ano := prec - clim] # add anomaly as another column print(dt) ## lon lat prec month year terc_cat clim ano ## 1: 22.0 -12.0 1.9301587 10 1981 -1 2.8169255 -0.886766778 ## 2: 22.0 -11.5 2.1351602 10 1981 -1 3.0905585 -0.955398264 ## 3: 22.0 -11.0 2.7692883 10 1981 -1 3.4675703 -0.698281996 ## 4: 22.0 -10.5 3.9201619 10 1981 0 3.8808617 0.039300191 ## 5: 22.0 -10.0 4.8720656 10 1981 1 4.2989969 0.573068714 ## --- ## 418076: 51.5 21.0 0.2404348 12 2020 -1 0.2559819 -0.015547112 ## 418077: 51.5 21.5 0.2184058 12 2020 -1 0.2415870 -0.023181188 ## 418078: 51.5 22.0 0.2053623 12 2020 -1 0.2151377 -0.009775418 ## 418079: 51.5 22.5 0.1615942 12 2020 -1 0.1870797 -0.025485473 ## 418080: 51.5 23.0 0.1387682 12 2020 -1 0.1701314 -0.031363167 ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, rr = c(-3,3)) Now, in this plot positive rainfall anomalies are shown red while negative anomalies are blue, which is very counterintuitive. The function allows us to specify the three used colors by name with the arguments low,mid, and high. So here's an anomaly plot looking a bit nicer: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, rr = c(-3,3), low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, name = &#39;mm/day&#39;) Note that we set the range argument to c(-3,3). Fixing the range makes mostly sense when the range is known (e.g. for correlation plots), or when you want to compare several plots (e.g. for comparing mean square error of different NWP models, all plots should have the same range). If we leave the range argument rr free, the range is determined from the data. However, when we do this for our anomaly plot this has an undesired sideeffect: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, name = &#39;mm/day&#39;) The color scale is no longer centered (white) at 0, but in the center of the (now asymetric) range. As a consequence, all gridpoints with anomaly 0 are shown in a light red. To fix this we can use the midpoint argument: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) Another, maybe surprising, use for the midpoint argument is that we can generate plots with a colorscale with only two colors. For example, going back to plotting the observed rainfall we can do the following: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;prec&#39;, mn = &#39;October 2020 rainfall&#39;, mid = &#39;white&#39;, high = &#39;blue&#39;, midpoint = 0, name = &#39;mm/day&#39;) What happens here is that we set the midpoint to 0, which is the minimum of our data (since observed rainfall is never below 0). Consequently the second half of the colorscale extending below 0 is ignored. Finally, the function allows to discretize the color scale. To this end we need to set the argument discrete_cs to TRUE. We can then control the breaks of the discrete colorscale by either of the arguments binwidth, n.breaks, or breaks (the latter takes a vector containing all breakpoints). To revisit the anomaly plot from above: ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) One final remark: Often you will deal with data tables that contain spatio-temporal data. It is then important to subselect the particular timeslice you want to plot before plotting (as we did above when we plotted October 2020). The function ggplot_dt by default tries to select the first timeslice of tempo-spatial data. This is often not what you want (which is why you should subselect first), but it's frequently handy for quick data diagnostics, which is the reason for this default behavior. Here an example: print(chirps_monthly) # a data table with multiple months and years and locations, so spatio-temporal data ## lon lat prec month year terc_cat ## 1: 22.0 -12.0 1.9301587 10 1981 -1 ## 2: 22.0 -11.5 2.1351602 10 1981 -1 ## 3: 22.0 -11.0 2.7692883 10 1981 -1 ## 4: 22.0 -10.5 3.9201619 10 1981 0 ## 5: 22.0 -10.0 4.8720656 10 1981 1 ## --- ## 418076: 51.5 21.0 0.2404348 12 2020 -1 ## 418077: 51.5 21.5 0.2184058 12 2020 -1 ## 418078: 51.5 22.0 0.2053623 12 2020 -1 ## 418079: 51.5 22.5 0.1615942 12 2020 -1 ## 418080: 51.5 23.0 0.1387682 12 2020 -1 ggplot_dt(chirps_monthly) # generates a plot of the precipitation of October 1981 (first timeslice), for a first quick impression how your data looks 2.1 Plotting values for selected countries Above, we have already seen an option how to restrict a plot to a particular country: by manually subsetting the data to a rectangle of longitudes and latitudes containing that specific country. This is of course quite tedious, and to make our lives easier we can use the restrict_to_country-function that takes a data table and a country name, and subsets the data table to only contain gridpoints in the specified country. Currently, the function accepts the following country names: Burundi, Eritrea, Ethiopia, Kenya, Rwanda, Somalia, South Sudan, Sudan, Tansania, Uganda. dt_new = restrict_to_country(dt[month == 10 &amp; year == 2020],&#39;Kenya&#39;) print(dt_new) ## lon lat prec month year terc_cat clim ano ## 1: 34.0 -1.0 4.9593979 10 2020 1 2.964475 1.9949232 ## 2: 34.0 -0.5 4.7645891 10 2020 1 3.639693 1.1248956 ## 3: 34.0 0.0 4.6154697 10 2020 1 4.284345 0.3311242 ## 4: 34.5 -1.0 7.5550100 10 2020 1 4.380272 3.1747380 ## 5: 34.5 -0.5 6.4341863 10 2020 1 4.056996 2.3771907 ## --- ## 187: 41.0 -1.0 0.7533339 10 2020 -1 2.456691 -1.7033568 ## 188: 41.0 3.0 1.1354665 10 2020 0 2.135546 -1.0000791 ## 189: 41.0 3.5 1.5012010 10 2020 0 2.191273 -0.6900723 ## 190: 41.0 4.0 1.8609376 10 2020 0 2.431412 -0.5704748 ## 191: 41.5 3.5 1.3543324 10 2020 0 2.447758 -1.0934261 ggplot_dt(dt_new, &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) As we can see, the function restricts the data to all gridcells for which the centerpoint lies within the specified country. This is useful, for example, for calculating mean scores for the specified country. However, it is not optimal for plotting since every grid cell past the border is censored even though the original data table contained values there. To this end, the restrict_to_country function has a rectangle-argument that you can set to TRUE for plotting: dt_new = restrict_to_country(dt[month == 10 &amp; year == 2020],&#39;Kenya&#39;, rectangle = TRUE) ggplot_dt(dt_new, &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) Instead of a single country name you can also pass multiple country names in a vector to the function. Moreover, when you use rectangle = TRUE, you can specify a tolerance tol in order to widen the plotting window: dt_new = restrict_to_country(dt[month == 10 &amp; year == 2020], c(&#39;Kenya&#39;,&#39;Tanzania&#39;), rectangle = TRUE,tol = 2) ggplot_dt(dt_new, &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, discrete_cs = TRUE, binwidth = 2, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) The tol = 2 argument means that the function will include a buffer zone of 2 degrees lon/lat outside the specified countries (i.e. 4 gridpoints to each side). Note that the buffer to the south of Tanzania is smaller, because the original data table dt does not contain any data further south. 2.2 More plotting options The function ggplot_dt is, as its name suggests, based on the package ggplot2. In ggplot2, plots are composed out of multiple layers, allowing for successive adding of layers. This can help us to generate highly customized plots. As an example, let's revisit the anomaly plot from above and add the location of Nairobi an Addis Abbaba to it: library(ggplot2) # get locations as data table: loc = data.table(name = c(&#39;Addis Abbaba&#39;,&#39;Nairobi&#39;),lon = c(38.77,36.84),lat = c(9,-1.28)) print(loc) ## name lon lat ## 1: Addis Abbaba 38.77 9.00 ## 2: Nairobi 36.84 -1.28 pp = ggplot_dt(dt[month == 10 &amp; year == 2020], &#39;ano&#39;, mn = &#39;October 2020 rainfall anomaly&#39;, low = &#39;red&#39;, mid = &#39;white&#39;, high = &#39;darkgreen&#39;, midpoint = 0, name = &#39;mm/day&#39;) + geom_point(data = loc,mapping = aes(x = lon,y = lat)) + geom_text(data = loc,mapping = aes(x = lon,y = lat,label = name),vjust = 1.5) print(pp) Here, we added two layers to the original plot, the first one being the geom_point-layer that creates the two points at the locations of the cities, and the second being the geom_text-layer that labels the points by the city names. ggplot2 is a widely used package and there is a large variety of tutorials and books out there that can help you getting familiar with the syntax. A frequently required operation is the changing of the font sizes of title and labels. The easiest way to do this is the command theme_set(theme_bw(base_size = 16)) # defaults to 12 print(pp) If we want to print the plot to an external file, all we have to do is pdf(file = &#39;&lt;path to file and filename&gt;.pdf&#39;, width = ...,height = ...) print(pp) dev.off() This prints a .pdf file, but you can print .png and some other file formats similarly, see ?Devices for an overview. We can also use ggplots adding-layer-syntax to overwrite existing layers, for example if we want a fully customized colorscale: library(viridis) # the viridis package contains some nice color scales ## Loading required package: viridisLite pp_new = pp + scale_fill_viridis(name = &#39;my_color_scale&#39;, breaks = seq(-5,5,by = 2), guide = guide_colorbar(title = &#39;my personal color scale&#39;, title.position = &#39;top&#39;, barwidth = 20, direction = &#39;horizontal&#39;)) + theme(legend.position = &#39;bottom&#39;) ## Scale for &#39;fill&#39; is already present. Adding another scale for &#39;fill&#39;, which ## will replace the existing scale. print(pp_new) "],["evaluation-examples.html", "3 Evaluation Examples 3.1 Data import with netcdf_to_dt 3.2 Tercile Forecasts 3.3 Exceedence probabilities 3.4 Temperature", " 3 Evaluation Examples 3.1 Data import with netcdf_to_dt We now provide some hands on examples for data import, data analysis and evaluation using the SeaVal package. The setup is as follows: library(ggpubr) # allows slightly fancier plots, see below data_dir = &#39;/nr/project/stat/CONFER/Data/validation/example_data/202102/&#39; # the directory the data is stored in The key function for importing netcdf files is netcdf_to_dt, which just takes the name of the netcdf (including directory path): fn = &quot;CorrelationSkillRain_Feb-Apr_Feb2021.nc&quot; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/validation/example_data/202102/CorrelationSkillRain_Feb-Apr_Feb2021.nc (NC_FORMAT_CLASSIC): ## ## 1 variables (excluding dimension variables): ## float corr[lon,lat] ## lead: 0 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 0 ## time: 13 ## _FillValue: -9999 ## ## 3 dimensions: ## time Size:0 *** is unlimited *** ## [1] &quot;vobjtovarid4: **** WARNING **** I was asked to get a varid for dimension named time BUT this dimension HAS NO DIMVAR! Code will probably fail at this point&quot; ## lat Size:77 ## units: degrees_north ## lon Size:66 ## units: degrees_east ## ## 6 global attributes: ## units: mm ## MonInit_month: 2 ## valid_time: Feb-Apr ## creation_date: Mon Feb 15 06:59:57 EAT 2021 ## Conventions: None ## title: Correlation between Cross-Validated and Observed Rainfall By default, the function prints out all the information it gets from the netcdf, which is often useful. This can be turned off by the verbose argument of the function, see ?netcdf_to_dt. As we can see, the netcdf consists of a single variable (and the two dimension variables lon and lat). The resulting data table looks like this: print(dt) ## lon lat corr ## 1: 20.5 -13.5 NA ## 2: 21.0 -13.5 NA ## 3: 21.5 -13.5 NA ## 4: 22.0 -13.5 NA ## 5: 22.5 -13.5 NA ## --- ## 5078: 51.0 24.5 NA ## 5079: 51.5 24.5 NA ## 5080: 52.0 24.5 NA ## 5081: 52.5 24.5 NA ## 5082: 53.0 24.5 NA ggplot_dt(dt, mn = &#39;Corr. skill rain Feb-Apr, Feb initialized&#39;, # title rr = c(-1,1), # range of the colorbar discrete_cs = TRUE,binwidth = 0.4, # discretize colorbar guide = guide_colorbar(barwidth = 0.5, barheight = 10)) # make colorbar longer We can compare to the March initialized forecast: fn = &quot;CorrelationSkillRain_Mar-May_Feb2021.nc&quot; dt = netcdf_to_dt(paste0(data_dir,fn),verbose = 0) ggplot_dt(dt, mn = &#39;Corr. skill rain Mar-May, Mar initialized&#39;, # title rr = c(-1,1), # range of the colorbar discrete_cs = TRUE,binwidth = 0.4, # discretize colorbar guide = guide_colorbar(barwidth = 0.5, barheight = 10)) # make colorbar longer Next, let us look at a more elaborate example of crossvalidation. In our example folder we have two crossvalidation datasets and corresponding observations (one for FMA, one for MAM). We will process them simultaneously here, to highlight more data.table syntax. ##### CrossValidatedPredictedRain_Feb-Apr_Feb2021.nc ##### fn_pred1 = &quot;CrossValidatedPredictedRain_Feb-Apr_Feb2021.nc&quot; fn_pred2 = &quot;CrossValidatedPredictedRain_Mar-May_Feb2021.nc&quot; dt_pred1 = netcdf_to_dt(paste0(data_dir,fn_pred1),verbose = 0) # they look the same, we can just look at the information from one of them... dt_pred2 = netcdf_to_dt(paste0(data_dir,fn_pred2)) ## File /nr/project/stat/CONFER/Data/validation/example_data/202102/CrossValidatedPredictedRain_Mar-May_Feb2021.nc (NC_FORMAT_CLASSIC): ## ## 1 variables (excluding dimension variables): ## float prec[lon,lat,time] ## lead: 1 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 1 ## _FillValue: -9999 ## ## 3 dimensions: ## time Size:35 *** is unlimited *** ## units: months since 1981-01-01 ## calendar: standard ## _FillValue: 9.96920996838687e+36 ## lat Size:77 ## units: degrees_north ## lon Size:66 ## units: degrees_east ## ## 6 global attributes: ## units: mm ## MonInit_month: 2 ## valid_time: Mar-May ## creation_date: Mon Feb 15 06:59:57 EAT 2021 ## Conventions: None ## title: Cross Validated Predicted Rainfall Total (mm) # add a column, identifying which is which: dt_pred1[,season:= &#39;FMA&#39;] dt_pred2[,season:= &#39;MAM&#39;] # bind together dt_pred = rbindlist(list(dt_pred1,dt_pred2)) print(dt_pred) ## lon lat time prec season ## 1: 20.5 -13.5 13 NA FMA ## 2: 21.0 -13.5 13 NA FMA ## 3: 21.5 -13.5 13 NA FMA ## 4: 22.0 -13.5 13 NA FMA ## 5: 22.5 -13.5 13 NA FMA ## --- ## 355736: 51.0 24.5 421 NA MAM ## 355737: 51.5 24.5 421 NA MAM ## 355738: 52.0 24.5 421 NA MAM ## 355739: 52.5 24.5 421 NA MAM ## 355740: 53.0 24.5 421 NA MAM # get observations: fn_obs1 = &quot;ObservedRain_Feb-Apr_Feb2021.nc&quot; fn_obs2 = &quot;ObservedRain_Mar-May_Feb2021_update.nc&quot; dt_obs1 = netcdf_to_dt(paste0(data_dir,fn_obs1),verbose = 0) dt_obs2 = netcdf_to_dt(paste0(data_dir,fn_obs2),verbose = 1) ## Units: ## prec: ## time: months since 1981-01-01 ## lat: degrees_north ## lon: degrees_east dt_obs1[,season := &#39;FMA&#39;] dt_obs2[,season := &#39;MAM&#39;] dt_obs = rbindlist(list(dt_obs1,dt_obs2)) # merge predictions and observations into the same data table: setnames(dt_pred,&#39;prec&#39;,&#39;prediction&#39;) setnames(dt_obs,&#39;prec&#39;,&#39;observation&#39;) dt = merge(dt_pred,dt_obs,by = c(&#39;lon&#39;,&#39;lat&#39;,&#39;time&#39;,&#39;season&#39;)) print(dt) ## lon lat time season prediction observation ## 1: 20.5 -13.5 13 FMA NA NA ## 2: 20.5 -13.5 13 MAM NA NA ## 3: 20.5 -13.5 25 FMA NA NA ## 4: 20.5 -13.5 25 MAM NA NA ## 5: 20.5 -13.5 37 FMA NA NA ## --- ## 355736: 53.0 24.5 397 MAM NA NA ## 355737: 53.0 24.5 409 FMA NA NA ## 355738: 53.0 24.5 409 MAM NA NA ## 355739: 53.0 24.5 421 FMA NA NA ## 355740: 53.0 24.5 421 MAM NA NA # remove all rows with missing predictions: dt = dt[!is.na(prediction)] # convert time from the &#39;months since date&#39; (MSD) format to years and months (YM) dt = MSD_to_YM(dt,origin = &#39;1981-01-01&#39;) # (the origin was documented in the netcdf, see above.) print(dt) ## lon lat season prediction observation year month ## 1: 20.5 -11.5 FMA 316.19452 369.36932 1982 2 ## 2: 20.5 -11.5 MAM 202.94411 208.28058 1982 2 ## 3: 20.5 -11.5 FMA 316.20178 252.47144 1983 2 ## 4: 20.5 -11.5 MAM 205.24921 161.22548 1983 2 ## 5: 20.5 -11.5 FMA 317.43375 267.44031 1984 2 ## --- ## 167330: 51.5 22.5 FMA 25.44651 19.71902 2012 2 ## 167331: 51.5 22.5 FMA 25.59836 27.55773 2013 2 ## 167332: 51.5 22.5 FMA 26.03941 25.14965 2014 2 ## 167333: 51.5 22.5 FMA 26.03053 22.23634 2015 2 ## 167334: 51.5 22.5 FMA 26.00327 34.84376 2016 2 We now have the data table in the shape we want it to be, containing both predictions and observations as one column each, which makes it easy to compare: ### check out local biases ### bias_dt = dt[,.(bias = mean(prediction - observation)), by = .(lon,lat,season)] # grouping by lon,lat, and season means that the mean is taken over all years. bias_dt[,range(bias)] # get an idea of the range ## [1] -12.64276 15.80456 pp1 = ggplot_dt(bias_dt[season == &#39;FMA&#39;], data_col = &#39;bias&#39;, rr = c(-15,15), # fix range to make it comparable to pp2 mn = &#39;bias of FMA prediction&#39;, midpoint = 0) pp2 = ggplot_dt(bias_dt[season == &#39;MAM&#39;], data_col = &#39;bias&#39;, rr = c(-15,15), mn = &#39;bias of MAM prediction&#39;, midpoint = 0) # show plots: ggarrange(pp1,pp2) # here we need the package ggpubr We can use the function MSESS_dt to compute MSE skill scores. The skill is relative to leave-one-year-out climatology: ### analyze mean square error skill scores ### msess = MSESS_dt(dt, fc_col = &#39;prediction&#39;, obs_col = &#39;observation&#39;, by_cols = c(&#39;lon&#39;,&#39;lat&#39;,&#39;season&#39;)) # the skill scores should be computed for each location and each season separately # get range for plotting: msess[,range(MSESS)] ## [1] -0.3447786 0.3436327 rr = c(-0.35,0.35) pp1 = ggplot_dt(msess[season == &#39;FMA&#39;], data_col = &#39;MSESS&#39;, rr=rr, mn = &#39;MSE skill score, FMA&#39;) pp2 = ggplot_dt(msess[season == &#39;MAM&#39;], data_col = &#39;MSESS&#39;, rr=rr, mn = &#39;MSE skill score, MAM&#39;) ggarrange(pp1,pp2) If we want to analyze results by countries, we can use the function add_country_names that adds a column with country names to the data table: # check out average MSEs and MSESSs per country: msess = add_country_names(msess) print(msess) ## lon lat season MSE clim_MSE MSESS country ## 1: 23.0 11.0 MAM 303.14287 308.54726 0.017515586 Sudan ## 2: 23.5 9.0 MAM 751.99749 731.22747 -0.028404319 Sudan ## 3: 23.5 10.5 MAM 294.52421 297.75507 0.010850729 Sudan ## 4: 23.5 11.0 MAM 229.63428 228.55108 -0.004739428 Sudan ## 5: 24.0 9.0 MAM 426.41982 400.60929 -0.064428203 Sudan ## --- ## 2703: 50.0 11.0 MAM 185.52785 200.07593 0.072712761 Somalia ## 2704: 50.5 9.5 MAM 48.67772 46.13510 -0.055112437 Somalia ## 2705: 50.5 10.0 MAM 28.67013 27.39041 -0.046721342 Somalia ## 2706: 50.5 11.0 MAM 55.81477 54.05239 -0.032604992 Somalia ## 2707: 50.5 11.5 MAM 60.25333 60.52558 0.004498041 Somalia msess_by_country = msess[,.(MSE = mean(MSE), MSESS = mean(MSESS)), by = country] # take averages by country print(msess_by_country) ## country MSE MSESS ## 1: Sudan 358.0374 0.015229343 ## 2: South Sudan 901.2060 0.021752470 ## 3: Rwanda 1657.1758 0.129892834 ## 4: Tanzania 3588.8147 0.037472556 ## 5: Burundi 2263.1621 0.110301016 ## 6: Uganda 1578.1713 0.044870020 ## 7: Ethiopia 1863.0355 0.049708565 ## 8: Kenya 2404.1271 0.061263744 ## 9: Eritrea 447.6274 0.009834729 ## 10: Somalia 1121.8166 0.023641155 ## 11: Djibouti 111.1771 0.029694437 3.2 Tercile Forecasts Let us look at the tercile forecasts: fn = &#39;Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc&#39; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/validation/example_data/202102/Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc (NC_FORMAT_CLASSIC): ## ## 3 variables (excluding dimension variables): ## float below[lon,lat] ## average_op_ncl: dim_avg_n over dimension(s): model ## units: ## lead: 1 ## _FillValue: -9999 ## float normal[lon,lat] ## _FillValue: -9999 ## lead: 1 ## units: ## average_op_ncl: dim_avg_n over dimension(s): model ## float above[lon,lat] ## _FillValue: -9999 ## lead: 1 ## units: ## average_op_ncl: dim_avg_n over dimension(s): model ## ## 3 dimensions: ## time Size:0 *** is unlimited *** ## [1] &quot;vobjtovarid4: **** WARNING **** I was asked to get a varid for dimension named time BUT this dimension HAS NO DIMVAR! Code will probably fail at this point&quot; ## lat Size:381 ## units: degrees_north ## lon Size:326 ## units: degrees_east ## ## 7 global attributes: ## creation_date: Thu Feb 18 17:06:05 EAT 2021 ## Conventions: None ## source_file: Objective Forecast ## description: Obtained by averaging CPT and local regression ## title: Tercile Consolidated Objective Forecast ## history: Mon Feb 22 10:28:53 2021: ncrename -v LAT,lat Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## Mon Feb 22 10:28:43 2021: ncrename -v LON,lon Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## Mon Feb 22 10:28:26 2021: ncrename -d LON,lon Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## Mon Feb 22 10:27:42 2021: ncrename -d LAT,lat Ens_Prec_1monLead_MAM_Prob_EnsRegrCPT-avg.nc ## NCO: netCDF Operators version 4.9.3 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco) dt = dt[!is.na(below) | !is.na(normal) | !is.na (above)] p1 = ggplot_dt(dt,data_col = &#39;below&#39;, midpoint = dt[,min(below,na.rm = TRUE)]) p2 = ggplot_dt(dt,data_col = &#39;normal&#39;, midpoint = dt[,min(normal,na.rm = TRUE)], high = &#39;darkgoldenrod&#39;) # see https://www.r-graph-gallery.com/ggplot2-color.html for an overview of color names. p3 = ggplot_dt(dt,data_col = &#39;above&#39;, midpoint = dt[,min(above,na.rm = TRUE)], high = &#39;darkgreen&#39;) ggarrange(p1,p2,p3,ncol = 3) In order to evaluate the forecast we need precipitation data for 2021. fn = &quot;PredictedProbabilityRain_Mar-May_Feb2021_new.nc&quot; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/validation/example_data/202102/PredictedProbabilityRain_Mar-May_Feb2021_new.nc (NC_FORMAT_NETCDF4): ## ## 3 variables (excluding dimension variables): ## float normal[lon,lat] (Contiguous storage) ## _FillValue: -1 ## float above[lon,lat] (Contiguous storage) ## _FillValue: -1 ## lead: 1 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 2 ## float below[lon,lat] (Contiguous storage) ## _FillValue: -1 ## lead: 1 ## average_op_ncl: dim_avg_n over dimension(s): model ## type: 0 ## ## 2 dimensions: ## lat Size:77 ## _FillValue: NaN ## units: degrees_north ## lon Size:66 ## _FillValue: NaN ## units: degrees_east dt[,normal := normal/100][,above := above/100][,below := below/100] 3.3 Exceedence probabilities missing observations 3.4 Temperature ##### TrefEnsRegr_monthly.nc ##### fn = &#39;TrefEnsRegr_monthly.nc&#39; dt = netcdf_to_dt(paste0(data_dir,fn)) ## File /nr/project/stat/CONFER/Data/validation/example_data/202102/TrefEnsRegr_monthly.nc (NC_FORMAT_CLASSIC): ## ## 6 variables (excluding dimension variables): ## float below[lon,lat,model,lead] ## units: % ## _FillValue: -9999 ## float above[lon,lat,model,lead] ## units: % ## _FillValue: -9999 ## float normal[lon,lat,model,lead] ## units: % ## _FillValue: -9999 ## float corr[lon,lat,model,lead] ## units: cor ## _FillValue: -9999 ## float tref[lon,lat,model,lead] ## units: K ## _FillValue: -9999 ## float anom[lon,lat,model,lead] ## units: K ## _FillValue: -9999 ## ## 4 dimensions: ## lon Size:66 ## units: degreesE ## long_name: lon ## lat Size:77 ## units: degreesN ## long_name: lat ## model Size:5 ## units: number ## long_name: model ## lead Size:3 ## units: month ## long_name: lead # plot correlations of predictions for all five models at all lead_times: # create list of plots: plot_list = list() for(leadtime in 1:3) { for(mod in 1:5) { plot_list = c(plot_list,list(ggplot_dt(dt[model == mod &amp; lead == leadtime], &#39;corr&#39;, rr = c(-1,1), mn = paste0(&#39;model &#39;,mod,&#39;, lead &#39;,leadtime), discrete_cs = TRUE, binwidth = 0.2, guide = guide_colorbar(title = NULL, barwidth = 75, direction = &#39;horizontal&#39;)))) # adjust the legend/colorbar. } } #plot as grid: do.call(&#39;ggarrange&#39;, c(plot_list,ncol = 5,nrow = 3,common.legend = TRUE,legend = &#39;bottom&#39;)) "]]
